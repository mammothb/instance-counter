{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os.path\r\n",
    "import sys\r\n",
    "\r\n",
    "import cv2\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "from PIL import Image\r\n",
    "from six.moves import urllib\r\n",
    "\r\n",
    "ROOT_DIR = os.path.abspath(\"..\")\r\n",
    "sys.path.append(ROOT_DIR)\r\n",
    "\r\n",
    "\r\n",
    "from src.deeplab.config import DL_LABEL_MERGE, DL_LABEL_NAMES\r\n",
    "from src.deeplab.model import DeepLabModel\r\n",
    "import src.deeplab.visualize as dl_viz\r\n",
    "from src.mrcnn import utils\r\n",
    "import src.mrcnn.coco as coco\r\n",
    "from src.mrcnn.config import MRCNN_LABEL_NAMES\r\n",
    "from src.mrcnn.model import MaskRCNN\r\n",
    "import src.mrcnn.visualize as mrcnn_viz\r\n",
    "\r\n",
    "\r\n",
    "%matplotlib inline\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLab model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\r\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"weights\")\r\n",
    "\r\n",
    "# DeepLab\r\n",
    "DL_MODEL_PATH = os.path.join(MODEL_DIR, \"deeplab_model.tar.gz\")\r\n",
    "DL_URL = (\r\n",
    "    \"http://download.tensorflow.org/models/\"\r\n",
    "    \"deeplabv3_mnv2_ade20k_train_2018_12_03.tar.gz\"\r\n",
    ")\r\n",
    "\r\n",
    "if not os.path.exists(DL_MODEL_PATH):\r\n",
    "    print(\"Downloading DeepLab model...\")\r\n",
    "    urllib.request.urlretrieve(DL_URL, DL_MODEL_PATH)\r\n",
    "    print(\"Download complete, loading DeepLab model...\")\r\n",
    "\r\n",
    "DL_MODEL = DeepLabModel(DL_MODEL_PATH)\r\n",
    "print(\"DeepLab model loaded successfully!\")\r\n",
    "\r\n",
    "# MRCNN\r\n",
    "class InferenceConfig(coco.CocoConfig):\r\n",
    "    # Set batch size to 1 since we'll be running inference on\r\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\r\n",
    "    GPU_COUNT = 1\r\n",
    "    IMAGES_PER_GPU = 1\r\n",
    "\r\n",
    "MRCNN_MODEL_PATH = os.path.join(MODEL_DIR, \"mask_rcnn_coco.h5\")\r\n",
    "# Download COCO trained weights from Releases if needed\r\n",
    "if not os.path.exists(MRCNN_MODEL_PATH):\r\n",
    "    utils.download_trained_weights(MRCNN_MODEL_PATH)\r\n",
    "config = InferenceConfig()\r\n",
    "# Create model object in inference mode.\r\n",
    "MRCNN_MODEL = MaskRCNN(mode=\"inference\", model_dir=LOGS_DIR, config=config)\r\n",
    "\r\n",
    "# Load weights trained on MS-COCO\r\n",
    "MRCNN_MODEL.load_weights(MRCNN_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_PATH = os.path.join(ROOT_DIR, \"videos\", \"People_sample_2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(VIDEO_PATH)\r\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\r\n",
    "output_path = f\"{os.path.splitext(VIDEO_PATH)[0]}_processed.avi\"\r\n",
    "\r\n",
    "vid_writer = cv2.VideoWriter(\r\n",
    "    output_path,\r\n",
    "    cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\"),\r\n",
    "    fps,\r\n",
    "    (\r\n",
    "        round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\r\n",
    "        round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\r\n",
    "    ),\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "Done processing !!!\n",
      "Output file is stored as d:\\GitRepos\\instance-counter\\videos\\People_sample_2_processed.avi\n"
     ]
    }
   ],
   "source": [
    "sec = 0\r\n",
    "while True:\r\n",
    "    print(sec)\r\n",
    "    cap.set(1, sec * fps)\r\n",
    "    # Get frame from the video\r\n",
    "    has_frame, frame = cap.read()\r\n",
    "\r\n",
    "    # Stop the program if reached end of video\r\n",
    "    if not has_frame:\r\n",
    "        print(\"Done processing !!!\")\r\n",
    "        print(f\"Output file is stored as {output_path}\")\r\n",
    "        break\r\n",
    "\r\n",
    "    _, seg_map = DL_MODEL.run(Image.fromarray(frame[:, :, ::-1]))\r\n",
    "    seg_map = cv2.resize(\r\n",
    "        seg_map, frame.shape[:-1][::-1], interpolation=cv2.INTER_NEAREST\r\n",
    "    )\r\n",
    "    frame_copy = dl_viz.display_segmentation(\r\n",
    "        frame, seg_map, DL_LABEL_NAMES, DL_LABEL_MERGE\r\n",
    "    )\r\n",
    "\r\n",
    "    results = MRCNN_MODEL.detect([frame[:, :, ::-1]])\r\n",
    "    r = results[0]\r\n",
    "    frame_copy = mrcnn_viz.display_instances(\r\n",
    "        frame_copy,\r\n",
    "        r[\"rois\"],\r\n",
    "        r[\"masks\"],\r\n",
    "        r[\"class_ids\"],\r\n",
    "        MRCNN_LABEL_NAMES,\r\n",
    "        r[\"scores\"],\r\n",
    "    )\r\n",
    "\r\n",
    "    # Write the frame with the detection boxes\r\n",
    "    vid_writer.write(frame_copy.astype(np.uint8))\r\n",
    "    sec += 1\r\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has_frame, frame = cap.read()\r\n",
    "# _, seg_map = DL_MODEL.run(Image.fromarray(frame[:, :, ::-1]))\r\n",
    "# seg_map = cv2.resize(\r\n",
    "#     seg_map, frame.shape[:-1][::-1], interpolation=cv2.INTER_NEAREST\r\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display_segmentation_label(seg_map):\r\n",
    "#     \"\"\"Visualizes input image, segmentation map and overlay view.\"\"\"\r\n",
    "#     unique_labels = np.unique(DL_LABEL_MERGE[seg_map])\r\n",
    "#     ax = plt.subplot(1, 1, 1)\r\n",
    "#     plt.imshow(\r\n",
    "#         DL_COLOR_MAP[unique_labels].astype(np.uint8),\r\n",
    "#         interpolation=\"nearest\",\r\n",
    "#     )\r\n",
    "#     ax.yaxis.tick_right()\r\n",
    "#     plt.yticks(range(len(unique_labels)), DL_LABEL_NAMES[unique_labels])\r\n",
    "#     plt.xticks([], [])\r\n",
    "#     ax.tick_params(width=0.0)\r\n",
    "#     plt.grid(\"off\")\r\n",
    "#     plt.show()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_segmentation_label(seg_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_copy = dl_viz.display_segmentation(\r\n",
    "#     frame, seg_map, DL_LABEL_NAMES, DL_LABEL_MERGE\r\n",
    "# )\r\n",
    "# _, ax = plt.subplots(1, figsize=(16, 16))\r\n",
    "# height, width = frame_copy.shape[:2]\r\n",
    "# ax.set_ylim(height + 10, -10)\r\n",
    "# ax.set_xlim(-10, width + 10)\r\n",
    "# ax.axis(\"off\")\r\n",
    "# ax.imshow(frame_copy[:, :, ::-1])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = MRCNN_MODEL.detect([frame[:, :, ::-1]])\r\n",
    "# r = results[0]\r\n",
    "# frame_copy = mrcnn_viz.display_instances(\r\n",
    "#     frame_copy,\r\n",
    "#     r[\"rois\"],\r\n",
    "#     r[\"masks\"],\r\n",
    "#     r[\"class_ids\"],\r\n",
    "#     MRCNN_LABEL_NAMES,\r\n",
    "#     r[\"scores\"],\r\n",
    "# )\r\n",
    "\r\n",
    "# _, ax = plt.subplots(1, figsize=(16, 16))\r\n",
    "# height, width = frame_copy.shape[:2]\r\n",
    "# ax.set_ylim(height + 10, -10)\r\n",
    "# ax.set_xlim(-10, width + 10)\r\n",
    "# ax.axis(\"off\")\r\n",
    "# ax.imshow(frame_copy[:, :, ::-1])\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('mrcnn': conda)",
   "name": "python3613jvsc74a57bd0a4401751e03e5eff8414c85ecabdf49b3fe7902825fae0aba35b82c2ac9d033f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}